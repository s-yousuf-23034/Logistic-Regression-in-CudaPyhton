import warnings
warnings.filterwarnings("ignore")

import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from numba import cuda
import time
import math

# Define CUDA kernel
@cuda.jit
def logistic_regression_kernel(X, y, weights, bias, learning_rate, num_iterations):
    num_samples, num_features = X.shape

    def logistic_function(x):
        if x < -30:
            return 0
        elif x > 30:
            return 1
        else:
            return 1 / (1 + math.exp(-x))

    for _ in range(num_iterations):
        i = cuda.grid(1)

        if i < num_features:
            logits = 0.0
            for j in range(num_samples):
                logits += X[j, i] * weights[i]
            logits += bias[0]

            prediction = logistic_function(logits)

            d_weights = 0.0
            d_bias = 0.0
            for j in range(num_samples):
                d_weights += X[j, i] * (prediction - y[j])
                d_bias += prediction - y[j]

            d_weights /= num_samples
            d_bias /= num_samples

            weights[i] -= learning_rate * d_weights
            bias[0] -= learning_rate * d_bias



def logistic_regression():
  # Load the Iris dataset
  d = load_breast_cancer()
  X = d.data
  y = d.target

  # Split the data into training and testing sets
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

  # Transfer data to GPU
  X_train = np.float32(X_train)
  y_train = np.float32(y_train)
  X_train_gpu = cuda.to_device(X_train)
  y_train_gpu = cuda.to_device(y_train)

  # Initialize weights and bias
  num_features = X_train.shape[1]
  weights = np.zeros(num_features, dtype=np.float32)
  bias = np.zeros(1, dtype=np.float32)
  weights_gpu = cuda.to_device(weights)
  bias_gpu = cuda.to_device(bias)

  # Set learning rate and number of iterations
  learning_rate = 0.01
  num_iterations = 1000

  # # Start the timer
  # start_time = time.time()

  # Configure the CUDA grid and block dimensions
  threads_per_block = 32
  blocks_per_grid = (num_features + (threads_per_block - 1)) // threads_per_block

  # Launch the CUDA kernel
  logistic_regression_kernel[blocks_per_grid, threads_per_block](X_train_gpu, y_train_gpu, weights_gpu, bias_gpu, learning_rate, num_iterations)

  # # End the timer
  # end_time = time.time()

  # Transfer results back to CPU
  weights = weights_gpu.copy_to_host()
  bias = bias_gpu.copy_to_host()

  # # Calculate the execution time
  # execution_time = end_time - start_time

  # Perform inference on the test set
  logits_test = np.dot(X_test, weights) + bias
  predictions_test = (1 / (1 + np.exp(-logits_test))).round().astype(np.int32)

# Print the learned weights and bias
  print("Learned Weights:", weights)
  print("Learned Bias:", bias)

# Print the predicted labels for the test set
  print("Predictions for Test Set:", predictions_test)

# Print the execution time
%timeit logistic_regression()

